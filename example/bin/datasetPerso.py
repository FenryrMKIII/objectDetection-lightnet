import copy
import logging
from PIL import Image
import torch
from torchvision import transforms as tf
import brambox as bb
import lightnet as ln
from pathlib import Path

__all__ = ['valveDataset']
log = logging.getLogger('lightnet.valve.dataset')

# one needs to define  this function at the top of the module
# otherwhise, Python raises a "Can't picle local object error"
# when going multiprocessing
# This is apparently specific to Windows ... ?

def identify_file(img_id):
    root = Path(r"C:\Users\DAA426\myWork\objectDetection-lightnet\data\images\valves")
    return Path.joinpath(root, img_id + '.png')

class valveDataset(ln.models.BramboxDataset):
    """ valves dataset, with annotations generated by `brambox.io.parser.DarknetParser`

    Parameters:
    -----------
        anno_path (str or Path): Path to annotation location (must be parseable by DarknetParser)
        params (lightnet.engine.HyperParameters): Hyperparameters for this data (See Note)
        augment (boolean): Whether to perform data augmentation
        kwargs (optional): extra keyword arguments to pass on to the `brambox.io.load()` function

    Note:
    -----
        The hyperparameters object should at least contain the following attributes:

        - params.input_dimension (tuple): tuple containing base (width,height) for the network
        - params.class_label_map (list): List of class_labels (can be **None**, but this might lead to undeterministic behaviour)
        - params.anno_filter (str, optional): How to filter difficult annotations: ['ignore', 'rm', 'none']; Default **'none'**
        - params.flip (float): chance to flip the image
        - params.jitter (float): jitter percentage
        - params.hue (float): Hue change percentage
        - params.saturation (float): Saturation change percentage
        - params.value (float): Value change percentage
    """
    def __init__(self, anno_path, params, augment, **kwargs):        
        
        anno_path = Path(anno_path)
        anno = []
        for file in anno_path.iterdir():
            if file.suffix == ".txt":
                anno.append(file)

        # Create dataframe containig all annotations data
        # data has to be structured as expected i.e.
        # one data folder containing images & annotations structured like 
        #
        # image000.txt, image000.png
        # image001.txt, image000.png
        #
        # the names don't matter BUT they must be consistent between annotation & related picture
        # also the annotations must be in Darknet brambox format i.e.
        #
        # label xcenter ycenter width height
        #
        # all expressed relative to the total image width and height
        # origin for the coordinates is the bottom left corner of the picture

        def getImageDims(id):
            # hardcoded at the moment ... did not yet find/implemented a proper way
            root = Path(r"C:\Users\DAA426\myWork\objectDetection-lightnet\data\images\valves")
            im = Image.open(Path.joinpath(root, id + ".png"))
            width, height = im.size
            return (width, height)
            
        annos = bb.io.load(bb.io.parser.annotation.DarknetParser(getImageDims, params.class_label_map), anno)

        img_tf = ln.data.transform.Compose([tf.ToTensor()])
        anno_tf = None
        if augment :
            rf  = ln.data.transform.RandomFlip(params.flip)
            rc  = ln.data.transform.RandomJitter(params.jitter, True, 0.1)
            hsv = ln.data.transform.RandomHSV(params.hue, params.saturation, params.value)
            img_tf[0:0] = [hsv, rc, rf]
            anno_tf[0:0] = [rc, rf]




        super().__init__(annos, params.input_dimension, params.class_label_map, identify_file, img_tf, anno_tf)
